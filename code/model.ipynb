{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "user_log_format1 = pd.read_csv('../data/data_format1/user_log_format1.csv', dtype={'time_stamp':'str'})\n",
    "user_info_format1 = pd.read_csv('../data/data_format1/user_info_format1.csv')\n",
    "train_data_format1 = pd.read_csv('../data/data_format1/train_format1.csv')\n",
    "submission_data_format1 = pd.read_csv('../data/data_format1/test_format1.csv')\n",
    "\n",
    "data_train_format2 = pd.read_csv('../data/data_format2/train_format2.csv')\n",
    "data_submission_format2 = pd.read_csv('../data/data_format2/test_format2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print head of data_train_format2\n",
    "print(data_train_format2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag origin\n",
    "train_data_format1['origin'] = 'train'\n",
    "submission_data_format1['origin'] = 'test'\n",
    "submission_data_format1.drop(['prob'], axis=1, inplace=True)\n",
    "\n",
    "# Merge data\n",
    "train_test_matrix = \\\n",
    "    pd.concat([train_data_format1, submission_data_format1], ignore_index=True, sort=False)\n",
    "train_test_matrix = train_test_matrix.merge(user_info_format1, on='user_id', how='left')\n",
    "\n",
    "# Give same name to seller_id in user_log_format1 and user_info_format1\n",
    "user_log_format1.rename(columns={'seller_id':'merchant_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print if the column have null values\n",
    "print(train_test_matrix.isnull().sum()) # Number of label to predict: 261477\n",
    "print('\\n')\n",
    "print(user_log_format1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print range of all columns\n",
    "for col in train_test_matrix.columns:\n",
    "    print(f'{col}: {train_test_matrix[col].min()} - {train_test_matrix[col].max()}')\n",
    "print('\\n')\n",
    "\n",
    "for col in user_log_format1.columns:\n",
    "    print(f'{col}: {user_log_format1[col].min()} - {user_log_format1[col].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename gender column. 0 for female, 1 for male, 2 or NULL for unknown\n",
    "train_test_matrix['gender'] = train_test_matrix['gender'].map({\n",
    "    0: 'female',\n",
    "    1: 'male',\n",
    "    2: 'unknown'\n",
    "}).fillna('unknown')\n",
    "# Rename age_range column. NULL for unknown\n",
    "train_test_matrix['age_range'] = train_test_matrix['age_range'].map({\n",
    "    1: 'first group',\n",
    "    2: 'second group',\n",
    "    3: 'third group',\n",
    "    4: 'fourth group',\n",
    "    5: 'fifth group',\n",
    "    6: 'sixth group',\n",
    "    7: 'seventh group',\n",
    "    8: 'eighth group'\n",
    "}).fillna('unknown')\n",
    "\n",
    "# Rename action_type column. 0 for click, 1 for add-to-cart, 2 for purchase, 3 for add-to-favorite\n",
    "user_log_format1['action_type'] = user_log_format1['action_type'].map({\n",
    "    0: 'click',\n",
    "    1: 'add-to-cart',\n",
    "    2: 'purchase',\n",
    "    3: 'add-to-favorite'\n",
    "})\n",
    "# Fill in the missing values of brand_id with 0\n",
    "user_log_format1['brand_id'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print if the column have null values\n",
    "print(train_test_matrix.isnull().sum()) # Number of label to predict: 261477\n",
    "print('\\n')\n",
    "print(user_log_format1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print range of all columns\n",
    "for col in train_test_matrix.columns:\n",
    "    print(f'{col}: {train_test_matrix[col].min()} - {train_test_matrix[col].max()}')\n",
    "print('\\n')\n",
    "\n",
    "for col in user_log_format1.columns:\n",
    "    print(f'{col}: {user_log_format1[col].min()} - {user_log_format1[col].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "train_test_matrix['user_id'] = train_test_matrix['user_id'].astype('uint32')\n",
    "train_test_matrix['merchant_id'] = train_test_matrix['merchant_id'].astype('uint16')\n",
    "train_test_matrix['label'] = train_test_matrix['label'].astype('float64')\n",
    "train_test_matrix['origin'] = train_test_matrix['origin'].astype('category')\n",
    "train_test_matrix['age_range'] = train_test_matrix['age_range'].astype('category')\n",
    "train_test_matrix['gender'] = train_test_matrix['gender'].astype('category')\n",
    "\n",
    "user_log_format1['user_id'] = user_log_format1['user_id'].astype('uint32')\n",
    "user_log_format1['item_id'] = user_log_format1['item_id'].astype('uint32')\n",
    "user_log_format1['cat_id'] = user_log_format1['cat_id'].astype('uint16')\n",
    "user_log_format1['merchant_id'] = user_log_format1['merchant_id'].astype('uint16')\n",
    "user_log_format1['brand_id'] = user_log_format1['brand_id'].astype('int16')\n",
    "user_log_format1['time_stamp'] = pd.to_datetime('2016' + user_log_format1['time_stamp'], format='%Y%m%d')\n",
    "user_log_format1['action_type'] = user_log_format1['action_type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print range of all columns after conversion\n",
    "for col in train_test_matrix.columns:\n",
    "    if train_test_matrix[col].dtype.name == 'category' and not train_test_matrix[col].cat.ordered:\n",
    "        print(f'{col}: Cannot compute range on unordered categorical data')\n",
    "    elif train_test_matrix[col].dtype.kind in 'biufc':  # Numeric columns\n",
    "        print(f'{col}: {train_test_matrix[col].min()} - {train_test_matrix[col].max()}')\n",
    "    else:\n",
    "        print(f'{col}: Non-numeric or unsupported type')\n",
    "print('\\n')\n",
    "\n",
    "for col in user_log_format1.columns:\n",
    "    if user_log_format1[col].dtype.name == 'category' and not user_log_format1[col].cat.ordered:\n",
    "        print(f'{col}: Cannot compute range on unordered categorical data')\n",
    "    elif user_log_format1[col].dtype.kind in 'biufc':  # Numeric columns\n",
    "        print(f'{col}: {user_log_format1[col].min()} - {user_log_format1[col].max()}')\n",
    "    else:\n",
    "        print(f'{col}: Non-numeric or unsupported type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of train_test_matrix\n",
    "print(train_test_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_grouped_by_user_id = user_log_format1.groupby('user_id')\n",
    "\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_user_id['item_id'].nunique().reset_index().rename(columns={'item_id': 'u_iid'}),\n",
    "    on='user_id', how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_user_id['cat_id'].nunique().reset_index().rename(columns={'cat_id': 'u_cid'}),\n",
    "    on='user_id', how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_user_id['merchant_id'].nunique().reset_index().rename(columns={'merchant_id': 'u_mid'}),\n",
    "    on='user_id', how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_user_id['brand_id'].nunique().reset_index().rename(columns={'brand_id': 'u_bid'}),\n",
    "    on='user_id', how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_user_id['action_type'].value_counts().unstack().reset_index().rename(\n",
    "        columns={'click': 'u_click', 'add-to-cart': 'u_cart', 'purchase': 'u_purchase', 'add-to-favorite': 'u_fav'}),\n",
    "    on='user_id', how='left'\n",
    ")\n",
    "# Number of days between the first and the last action\n",
    "user_time = user_grouped_by_user_id['time_stamp'].agg(['min', 'max']).reset_index()\n",
    "user_time['u_days_between'] = (user_time['max'] - user_time['min']).dt.days\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_time[['user_id', 'u_days_between']], \n",
    "    on='user_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "del user_grouped_by_user_id, user_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of train_test_matrix\n",
    "print(train_test_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_grouped_by_merchant_id = user_log_format1.groupby('merchant_id')\n",
    "\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_merchant_id['user_id'].nunique().reset_index().rename(columns={'user_id': 'm_uid'}),\n",
    "    on='merchant_id', how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_merchant_id['item_id'].nunique().reset_index().rename(columns={'item_id': 'm_iid'}),\n",
    "    on='merchant_id', how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_merchant_id['cat_id'].nunique().reset_index().rename(columns={'cat_id': 'm_cid'}),\n",
    "    on='merchant_id', how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_merchant_id['brand_id'].nunique().reset_index().rename(columns={'brand_id': 'm_bid'}),\n",
    "    on='merchant_id', how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_grouped_by_merchant_id['action_type'].value_counts().unstack().reset_index().rename(\n",
    "        columns={'click': 'm_click', 'add-to-cart': 'm_cart', 'purchase': 'm_purchase', 'add-to-favorite': 'm_fav'}),\n",
    "    on='merchant_id', how='left'\n",
    ")\n",
    "# Number of days between the first and the last action\n",
    "merchant_time = user_grouped_by_merchant_id['time_stamp'].agg(['min', 'max']).reset_index()\n",
    "merchant_time['m_days_between'] = (merchant_time['max'] - merchant_time['min']).dt.days\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    merchant_time[['merchant_id', 'm_days_between']], \n",
    "    on='merchant_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "del user_grouped_by_merchant_id, merchant_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of train_test_matrix\n",
    "print(train_test_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_merchant_group = user_log_format1.groupby(['user_id', 'merchant_id'])\n",
    "\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_merchant_group.size().reset_index().rename(columns={0: 'um_action_count'}),\n",
    "    on=['user_id', 'merchant_id'], how='left'\n",
    ")\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_merchant_group[['item_id', 'cat_id', 'brand_id']].nunique().reset_index().rename(\n",
    "        columns={'item_id': 'um_iid', 'cat_id': 'um_cid', 'brand_id': 'um_bid'},\n",
    "    ),\n",
    "    on=['user_id', 'merchant_id'], how='left'\n",
    ")\n",
    "um_time = user_merchant_group['time_stamp'].agg(['min', 'max']).reset_index()\n",
    "um_time['um_days_between'] = (um_time['max'] - um_time['min']).dt.days\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    um_time[['user_id', 'merchant_id', 'um_days_between']],\n",
    "    on=['user_id', 'merchant_id'], how='left'\n",
    ")\n",
    "\n",
    "del user_merchant_group, um_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User buy click ratio\n",
    "train_test_matrix['u_bcr'] = \\\n",
    "    train_test_matrix['u_purchase'] / train_test_matrix['u_click']\n",
    "# Merchant buy click ratio\n",
    "train_test_matrix['m_bcr'] = \\\n",
    "    train_test_matrix['m_purchase'] / train_test_matrix['m_click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data_train_format2 and data_submission_format2\n",
    "data_format2 = pd.concat([data_train_format2, data_submission_format2], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the action_type\n",
    "def parse_activity_log(log):\n",
    "    log = str(log)\n",
    "    actions = log.split('#')\n",
    "    seq = []\n",
    "    for action in actions:\n",
    "        item = action.split(':')\n",
    "        if len(item) == 5:\n",
    "            item_id, cat_id, brand_id, time_stamp, action_type = item\n",
    "            seq.append({\n",
    "                'item_id': int(item_id),\n",
    "                'cat_id': int(cat_id),\n",
    "                'brand_id': int(brand_id),\n",
    "                'time_stamp': int(time_stamp),\n",
    "                'action_type': int(action_type)\n",
    "            })\n",
    "\n",
    "    return seq\n",
    "\n",
    "def count_actions(log):\n",
    "    return len(log)\n",
    "\n",
    "data_format2['parsed_log'] = data_format2['activity_log'].apply(parse_activity_log)\n",
    "data_format2['action_count'] = data_format2['parsed_log'].apply(count_actions)\n",
    "\n",
    "# Add number of actions to train_test_matrix on user_id\n",
    "data_format2_grouped_by_user_id = data_format2.groupby('user_id')\n",
    "\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    data_format2_grouped_by_user_id['action_count'].agg(['min', 'max', 'mean', 'std']).reset_index().rename(\n",
    "        columns={'min': 'u_ac_min', 'max': 'u_ac_max', 'mean': 'u_ac_mean', 'std': 'u_ac_std'}\n",
    "    ),\n",
    "    on='user_id', how='left'\n",
    ")\n",
    "\n",
    "del data_format2_grouped_by_user_id\n",
    "\n",
    "# Add number of actions to train_test_matrix on merchant_id\n",
    "data_format2_grouped_by_merchant_id = data_format2.groupby('merchant_id')\n",
    "\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    data_format2_grouped_by_merchant_id['action_count'].agg(['min', 'max', 'mean', 'std']).reset_index().rename(\n",
    "        columns={'min': 'm_ac_min', 'max': 'm_ac_max', 'mean': 'm_ac_mean', 'std': 'm_ac_std'}\n",
    "    ),\n",
    "    on='merchant_id', how='left'\n",
    ")\n",
    "\n",
    "del data_format2_grouped_by_merchant_id\n",
    "\n",
    "# Add number of actions to train_test_matrix on user meerchant pair\n",
    "user_merchant_group_format2 = data_format2.groupby(['user_id', 'merchant_id'])\n",
    "\n",
    "train_test_matrix = train_test_matrix.merge(\n",
    "    user_merchant_group_format2['action_count'].agg(['min', 'max', 'mean', 'std']).reset_index().rename(\n",
    "        columns={'min': 'um_ac_min', 'max': 'um_ac_max', 'mean': 'um_ac_mean', 'std': 'um_ac_std'}\n",
    "    ),\n",
    "    on=['user_id', 'merchant_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "del user_merchant_group_format2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of train_test_matrix\n",
    "print(train_test_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_test_matrix[train_test_matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = train_test_matrix[train_test_matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': True,\n",
    "    'device': 'gpu',\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'early_stopping_rounds': 10\n",
    "}\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[lgb_train, lgb_eval]\n",
    ")\n",
    "\n",
    "y_pred = gbm.predict(X_valid, num_iteration=gbm.best_iteration)\n",
    "auc_score = roc_auc_score(y_valid, y_pred)\n",
    "print(f\"LightGBM AUC: {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission\n",
    "submission = submission_data_format1[['user_id', 'merchant_id']]\n",
    "submission['prob'] = gbm.predict(test_data, num_iteration=gbm.best_iteration)\n",
    "submission.to_csv('./submission/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
